<app-header></app-header>

<div class="page-title">
  <h1>{{ project?.title }}</h1>
</div>

<div class="analysis-scroll-cue" *ngIf="showScrollCue && isTraffic" (click)="onScrollCueClick()">
  <span class="cue-text">{{ scrollCueText }}</span>
  <span class="cue-arrow">{{ scrollCueArrow }}</span>
</div>

<!-- Traffic Sign Interactive Demo -->
<section #demoSection *ngIf="isPdfProject && isTraffic" class="traffic-demo">
  <div class="traffic-demo-card">
    <h2>
      Try the Model
      <span style="font-size: 35px; opacity: 0.7;">üß†</span>
    </h2>

    <p class="demo-instructions">
      Click <strong>Generate</strong> to load random traffic signs from the dataset.
      Drag and drop one to see how the neural network classifies it.
    </p>

    <div class="generate-btn-wrapper">
      <button class="generate-btn" (click)="generateImages()" [disabled]="isGenerating">
        <span *ngIf="!isGenerating">
          {{ generatedImages.length ? 'Generate More' : 'Generate Traffic Signs' }}
        </span>
        <span *ngIf="isGenerating">Loading images‚Ä¶</span>
      </button>
    </div>

    <div *ngIf="showSlowApiMessage" class="model-status">
      API is loading ‚Äî first request may take a few minutes if it hasn‚Äôt been used recently. Please hold on. ‚è≥
    </div>

    <div *ngIf="isPredicting" class="loading-indicator">
      <p>Running model‚Ä¶</p>
    </div>

    <div class="image-grid" *ngIf="generatedImages.length && !isGenerating">
      <img *ngFor="let img of generatedImages" [src]="'data:image/png;base64,' + img.image" draggable="true"
        [class.active]="selectedImage === img.image" (dragstart)="
          $event.dataTransfer?.setData('text/plain', img.image)
        " />
    </div>

    <div class="drop-zone" [class.dragging]="isDragging" (dragover)="onDragOver($event)"
      (dragleave)="onDragLeave($event)" (drop)="onDrop($event)">
      <p *ngIf="!selectedImage">Drop a traffic sign here</p>

      <img *ngIf="selectedImage" [src]="'data:image/png;base64,' + selectedImage" class="dropped-image" />
    </div>

    <div class="model-status" *ngIf="showModelWorking">
      üß† Running model‚Ä¶ this may take a few seconds on first load ‚è≥
    </div>

    <div class="prediction-box" *ngIf="predictionResult">
      <h3>The model predicts the traffic sign is:</h3>
      <p>
        <strong>{{ predictionResult.prediction }}</strong><br />
        Confidence: {{ predictionResult.confidence | percent:'1.0-2' }}
      </p>
      <div class="confidence-bar-container">
        <div class="confidence-bar-fill" [style.width.%]="predictionResult.confidence * 100"></div>
      </div>
    </div>
  </div>
</section>


<div *ngIf="isPdfProject; else normalProjectLayout" class="project-container" #analysisSection>
  <aside class="sidebar">
    <ul>
      <li *ngFor="let section of sections" [class.active]="currentPage === section.page"
        (click)="scrollToSection(section.page)">
        {{ section.title }}
      </li>
    </ul>
  </aside>

  <div class="pdf-container" #pdfContainer>
    <button class="fullscreen-btn" (click)="toggleFullScreen()">
      {{ isFullscreen ? '‚®â' : '‚§¢' }}
    </button>

    <pdf-viewer *ngIf="currentPage !== null" [src]="project?.pdfUrl" [render-text]="true" [page]="currentPage">
    </pdf-viewer>
  </div>
</div>

<section *ngIf="isPdfProject && isTraffic" class="overview-results">
  <div class="overview">
    <h2>Overview</h2>
    <p>
      This project is a traffic sign classification system built using a Convolutional Neural Network (CNN). The goal
      was to train a model that can correctly identify different types of traffic signs from images, such as speed
      limits, warnings, and directional signs. I used the German Traffic Sign Recognition Benchmark (GTSRB), which has
      images from 43 different traffic sign classes taken under various photo quality.

      I built and trained the model in Python using TensorFlow and Keras. I focused on proper image preprocessing, model
      design, and evaluation. After training, I deployed the model as a live API and connected it to this website so
      users can interact with it directly. The demo above allows users to generate random traffic sign images from the
      dataset and drag one into the model to see how it is classified in real time. This setup mirrors how a real
      image-based classification system would work in practice.
    </p>
  </div>

  <div class="results">
    <h2>Results</h2>
    <p>
      ‚Ä¢ The CNN achieved ~99% accuracy on the validation dataset across 43 traffic sign classes.<br>
      ‚Ä¢ Most classes show very high precision and recall, especially common signs like speed limits, stop signs, and
      priority signs.<br>
      ‚Ä¢ Misclassifications were rare and mostly occurred between visually similar signs, such as different curve
      warnings or speed limits.<br>
      ‚Ä¢ The confusion matrix confirms that the model correctly classifies the vast majority of images with very few
      errors.<br>
      ‚Ä¢ For individual predictions, the model outputs a confidence score, which is displayed in the live demo to show
      how certain the model is about each result.<br>
      ‚Ä¢ The model performs well enough to be used in a real-time, interactive setting, as demonstrated by the
      drag-and-drop feature on this website.<br>
    </p>
  </div>
</section>

<section *ngIf="isPdfProject && isPropertyPrice" class="overview-results">
  <div class="overview">
    <h2>Overview</h2>
      <p>
        This project explores how different machine learning models behave when applied to historical housing data from the
        1990 California Census. Each data point represents a census block group rather than an individual home, with features
        describing income levels, population, housing characteristics, and geographic location.
      </p>
      <br>
      <p>
        The main goal of the project was to understand which factors are most strongly related to housing prices and to compare
        several machine learning models, including linear regression, decision trees, random forests, and XGBoost. Rather than
        focusing on real-world price prediction, the emphasis is on model performance, feature importance, and understanding
        where and why certain models succeed or fail. This project highlights how income and location drive housing prices, as
        well as the limitations of using aggregated historical data for prediction.
      </p>
  </div>

  <div class="results">
    <h2>Results</h2>
      <p>
        ‚Ä¢ Model Performance: I compared several models and found that XGBoost performed the best. It achieved an R¬≤ score of
        about 0.84, meaning it explains roughly 84% of the variation in house prices. This was an improvement over the tuned
        Random Forest (R¬≤ ‚âà 0.81), as well as the decision tree and linear regression models.<br>

        ‚Ä¢ Error Metrics: XGBoost also had the lowest errors. The mean absolute error was about $30,000, which means that, on
        average, the model‚Äôs predictions were off by around $30k. The tuned Random Forest had an MAE closer to $32,000, and
        linear regression performed much worse with errors closer to $49,000.<br>

        ‚Ä¢ Feature Importance: Median income was the most important feature across all tree-based models. Location also mattered
        a lot, especially whether a neighborhood was inland or closer to the coast. These features had a much bigger impact
        than simple counts like total rooms or total bedrooms.<br>

        ‚Ä¢ Household Ratios: Creating features like rooms per household and population per household helped the models capture
        differences in housing density and slightly improved prediction accuracy compared to using the raw counts alone.<br>

        ‚Ä¢ Prediction Behavior: The models generally behaved as expected, predicting lower prices for inland, lower-income
        areas and higher prices for coastal, higher-income areas. Because the data comes from the 1990 census and represents
        aggregated districts rather than individual homes, this project focuses more on comparing models and understanding
        patterns than making precise modern-day price predictions.<br>
      </p>
  </div>
</section>

<section *ngIf="isPdfProject && isHomeFieldAdvantage" class="overview-results">
  <div class="overview">
    <h2>Overview</h2>
    <p>
      Home-field advantage is a widely debated phenomenon in professional sports, particularly in the NFL.
      Many believe that playing at home gives teams a significant edge due to factors like travel fatigue,
      crowd energy, and environmental familiarity. This project examines the impact of home-field advantage
      using data from 57 NFL seasons (1966-2023), analyzing over 14,000 games. The goal is to quantify the extent
      of home-field advantage and determine what factors contribute most to its effect on game outcomes.
    </p>
  </div>

  <div class="results">
    <h2>Results</h2>
    <p>
      ‚Ä¢ Overall Win Rate: Home teams won 58% of games, while away teams won 42%.<br>
      ‚Ä¢ Point Margins: Home teams, on average, won by 2+ points more than away teams.<br>
      ‚Ä¢ Travel Distance Impact: Teams traveling longer distances had lower win rates,
      with a sharp drop for very long travel (49.2%) compared to moderate travel (57‚Äì58%).<br>
      ‚Ä¢ Playoff vs. Regular Season: Home-field advantage was even stronger in playoff games,
      with home teams winning 65.9% of the time and winning by an average of 6.15 points.<br>
      ‚Ä¢ Rivalry Games: Home teams still had an advantage, but rivalry games were closer contests,
      with a significantly smaller win margin compared to non-rivalry games.<br>
    </p>
  </div>
</section>


<ng-template #normalProjectLayout> <!-- Non pdf projects -->
  <section class="project-details">

    <div class="video-container" *ngIf="isVideoProject">
      <video controls>
        <source [src]="project?.videoUrl" type="video/mp4" />
        <source [src]="project?.videoUrl" type="video/quicktime" />
        Your browser does not support the video tag.
      </video>
    </div>

    <div *ngIf="project.type === 'personal'" class="personal-website">
      <p>{{ project.description }}</p>
      <p>{{project.contactMessage}}</p>
    </div>

    <div class="overview-tools-container">
      <section class="overview" *ngIf="project.title === 'Investment App'">
        <h2>Overview</h2>
        <p>
          The Investment App is a simple yet powerful tool designed to help users estimate their potential returns based
          on key investment factors. This demo version focuses on calculating future gains using an initial investment,
          monthly contributions, and a given interest rate over time. With a clean and intuitive interface, users can
          quickly input their values and see how their investments grow. While it doesn‚Äôt include real-time stock
          tracking, this app provides a straightforward way to visualize the impact of compound interest and smart
          financial planning.
        </p>
      </section>
      <section class="overview" *ngIf="project.title === 'Task Management System'">
        <h2>Overview</h2>
        <p>
          The Task Management App is a tool designed for team collaboration and productivity. It allows users to add,
          assign, edit, and complete tasks while managing multiple team members effortlessly. With specific controls,
          you can track progress, update responsibilities, and ensure nothing falls through the cracks. Whether you‚Äôre
          coordinating a small group or overseeing a large project, this system keeps everyone on the same page, making
          task management efficient and hassle-free.
        </p>
      </section>
      <section class="overview" *ngIf="project.title === 'Pediatric Dashboard (Kaiser Permanente)'">
        <h2>Overview</h2>
        <p>
          The Pediatric Dashboard is a project I built during my time as a Data Scientist Intern at Kaiser Permanente.
          It‚Äôs an interactive dashboard that tracks key pediatric surgical metrics and helps clinical teams monitor
          trends in patient outcomes. I organized and cleaned ACS NSQIP data, (American College of Surgeons National
          Surgical Quality Improvement Program) built the visuals, and structured everything so physicians and analysts
          can quickly find what they need. The goal was to make the data easier to understand and to support better
          decision-making in real clinical settings. One of the highlights of this project was the Opioid Reduction
          Project, which analyzed the frequency and dosage of opioids prescribed post-surgery, helping identify what
          doctors at what Kaiser Permanente locations were overprescribing and where improvements could be made.

        </p>
      </section>

      <section class="tools" *ngIf="project.title === 'Investment App'
            || project.title === 'Task Management System'
            || project.title === 'Pediatric Dashboard (Kaiser Permanente)'">

        <h2>Tools Used</h2>
        <div class="tool-logos">
          <img *ngFor="let tool of project.techStack" [src]="toolLogos[tool] || '/assets/logos/default.png'"
            [alt]="tool" [title]="tool">
        </div>
      </section>

    </div>
  </section>
</ng-template>



<section class="github-section" *ngIf="project.title !== 'Pediatric Dashboard (Kaiser Permanente)'">
  <h2>View the Code!</h2>
  <a *ngIf="project?.githubLink" [href]="project.githubLink" target="_blank" class="github-btn">
    <img src="assets/githublogo.png" alt="GitHub Logo" />
  </a>
</section>
<app-contact></app-contact>